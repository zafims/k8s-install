==================== Install Kubernetes cluster on Ubuntu server 22.04 ==================

This article will guide you through the steps to install and configure a Kuberntes cluster on Ubuntu server.

1. Configuration

		--> Operating system version: Ubuntu Server 22.04 & 23
		--> Kubernetes cluster: 01 Master, 02 Worker

		Node	  IP	          hostname
		master	159.65.148.232   k8s-master
		worker	64.227.177.186  k8s-worker


2. Proceed

timedatectl set-timezone Australia/Sydney
sudo apt update
sudo apt upgrade -y

--> After the update is complete, we restart the servers
sudo reboot

--> Set hostname and update hosts file

		Master node
		sudo hostnamectl set-hostname "k8s-master"
		Workers
		sudo hostnamectl set-hostname "k8s-worker"

--> Next we update the /etc/hostsfile files of All Nodes
sudo apt install -y nano
sudo nano /etc/hosts

Then add below the file the following content:
159.65.148.232    k8s-master
64.227.177.186   k8s-worker

--> Disable swap and update kernel
		Note:
		The commands below execute on All Nodes

sudo swapoff -a

--> Check to see if swap is disabled or not with the command free -h. If successful, the result will be as follows:

$ free -h
               total        used        free      shared  buff/cache   available
Mem:           7.7Gi       167Mi       7.1Gi       1.0Mi       437Mi   7.3Gi
Swap:             0B          0B          0B

--> Next disable swap in/etc/fstab

sudo nano /etc/fstab
Find the line:  /           ext4   erros=remount-o 0       1
#/dev/vda2      none       swap       sw           0       0

--> Then run the following commands:

sudo mount -a
free -h

--> Load the following kernel modules on All the Nodes:

sudo tee /etc/modules-load.d/containerd.conf <<EOF
overlay
br_netfilter
EOF
sudo modprobe overlay
sudo modprobe br_netfilter

--> Set the following Kernel parameters for Kubernetes.

sudo tee /etc/sysctl.d/kubernetes.conf <<EOF
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
EOF

--> Then reload againsysctl
sudo sysctl --system

3. Install containerd run time

		Note:
		Run the commands below on All Nodes

sudo apt install -y curl gnupg2 software-properties-common apt-transport-https ca-certificates
sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmour -o /etc/apt/trusted.gpg.d/docker.gpg
sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"
sudo apt update
sudo apt install -y containerd.io

--> Once installed, we add the containerd configuration.
containerd config default | sudo tee /etc/containerd/config.toml >/dev/null 2>&1
sudo sed -i 's/SystemdCgroup \= false/SystemdCgroup \= true/g' /etc/containerd/config.toml
sudo systemctl restart containerd
sudo systemctl enable containerd

--> After the installation complete, we restart the servers
sudo reboot


4. Install Kubernetes
		Note:
		Run the commands below on All Nodes


sudo apt-get install -y apt-transport-https ca-certificates curl gpg

sudo mkdir -p -m 755 /etc/apt/keyrings
curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.30/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.30/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list

sudo apt-get update -y
sudo apt-get install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl


--> Initialize cluster using kubeadm
		Note:
		Run the command below only on the Master Node

sudo kubeadm config images pull
// sudo kubeadm init



sudo kubeadm init \
  --pod-network-cidr=10.10.0.0/16 \
  --control-plane-endpoint=159.65.148.232

# 159.65.148.232 = Master Node

--> Next, execute the commands below on the Master Node

mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config



--> Let's try running the command to check the status of the cluster

kubectl cluster-info
kubectl get nodes
kubectl get pods -n kube-system

5.1 Setup Calico Network

After initializing kubeadm, you need to setup Calico network in order to enable pod-to-pod communication. Run the following commands on the Master Node:

kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/tigera-operator.yaml
curl https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/custom-resources.yaml -O
sed -i 's/cidr: 192\.168\.0\.0\/16/cidr: 10.10.0.0\/16/g' custom-resources.yaml

kubectl create -f custom-resources.yaml

kubectl get pods -n kube-system

kubectl get nodes

5.2 Joining Nodes

We see that the control plane is running and there is currently only a master node, we will proceed to add a worker node to this cluster.

--> Add worker nodes to the cluster
		Note: The commands below only run on Worker Nodes

Let's review the output of the sudo kubeadm init command above and copy the command below:
Then you can join any number of worker nodes by running the following on each as root:

For Worker Node:
kubeadm join 142.171.91.203:6443 --token 6s6amr.jguibdx8irv4wf2r \
        --discovery-token-ca-cert-hash sha256:5ad474657d556045997240cd610580898f7f7b74574b091bdb47971f6b73b8cb --ignore-preflight-errors=all


For Additional Control Plane:
 kubeadm join 142.171.91.203:6443 --token 6s6amr.jguibdx8irv4wf2r \
        --discovery-token-ca-cert-hash sha256:5ad474657d556045997240cd610580898f7f7b74574b091bdb47971f6b73b8cb \
        --control-plane

--> on the control-plane to see this node join the cluster.
kubectl get nodes




===================================  MetalLB ( Master )===================================

# kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.14.8/config/manifests/metallb-native.yaml

# kubectl get ns
# kubectl get pods -n metallb-system
# kubectl get all  -n metallb-system
# kubectl get endpoints  -n metallb-system
